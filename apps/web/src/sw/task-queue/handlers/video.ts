/**
 * Video Generation Handler for Service Worker
 *
 * Handles video generation tasks with polling support.
 * ä½¿ç”¨é€šç”¨çš„åª’ä½“ç”Ÿæˆå·¥å…·å‡½æ•°æ¥å‡å°‘é‡å¤ä»£ç 
 */

import type { SWTask, TaskResult, HandlerConfig, TaskHandler } from '../types';
import { TaskExecutionPhase } from '../types';
import {
  mergeReferenceImages,
  pollVideoUntilComplete,
  fetchImageWithCache,
  parseSize,
  cropImageToAspectRatio,
} from '../utils/media-generation-utils';
import type { LLMReferenceImage } from '../llm-api-logger';

/**
 * Video generation response types
 */
interface VideoSubmitResponse {
  id: string;
  status: 'queued' | 'in_progress' | 'completed' | 'failed';
  progress: number;
  error?: string | { code: string; message: string };
}

/**
 * Submit response with log ID for tracking
 */
interface SubmitResult {
  response: VideoSubmitResponse;
  logId: string;
}

interface KlingSubmitResult {
  taskId: string;
  logId: string;
  action2: 'text2video' | 'image2video';
}

/**
 * Video generation handler
 */
export class VideoHandler implements TaskHandler {
  private abortControllers: Map<string, AbortController> = new Map();
  private pollingIntervals: Map<string, ReturnType<typeof setInterval>> =
    new Map();

  /**
   * Execute video generation task
   */
  async execute(task: SWTask, config: HandlerConfig): Promise<TaskResult> {
    const abortController = new AbortController();
    this.abortControllers.set(task.id, abortController);

    try {
      if (this.isKlingModel((task.params as any)?.model)) {
        return await this.executeKling(task, config, abortController.signal);
      }

      config.onProgress(task.id, 0, TaskExecutionPhase.SUBMITTING);

      // Submit video generation request
      const { response: submitResponse, logId } =
        await this.submitVideoGeneration(task, config, abortController.signal);

      // Notify remote ID
      config.onRemoteId(task.id, submitResponse.id);
      config.onProgress(task.id, 5, TaskExecutionPhase.POLLING);

      // Poll until completion using shared utility
      const result = await this.pollUntilComplete(
        submitResponse.id,
        task.id,
        config,
        abortController.signal,
        logId
      );

      return result;
    } finally {
      this.cleanup(task.id);
    }
  }

  /**
   * Resume video generation polling
   * æ¢å¤ä»»åŠ¡åªæ˜¯ç»§ç»­è½®è¯¢ï¼Œä¸åˆ›å»ºæ–°çš„ LLM API æ—¥å¿—æ¡ç›®
   * é€šè¿‡ taskId æŸ¥æ‰¾åŸå§‹æ—¥å¿—å¹¶åœ¨å®Œæˆæ—¶æ›´æ–°å®ƒ
   */
  async resume(task: SWTask, config: HandlerConfig): Promise<TaskResult> {
    if (!task.remoteId) {
      throw new Error('No remote ID for resume');
    }

    const abortController = new AbortController();
    this.abortControllers.set(task.id, abortController);

    // æŸ¥æ‰¾åŸå§‹ä»»åŠ¡çš„æ—¥å¿— IDï¼Œä»¥ä¾¿åœ¨è½®è¯¢å®Œæˆæ—¶æ›´æ–°å®ƒ
    const { findLatestLogByTaskId } = await import('../llm-api-logger');
    const originalLog = await findLatestLogByTaskId(task.id);
    const logId = originalLog?.id;

    try {
      if (this.isKlingModel((task.params as any)?.model)) {
        return await this.resumeKling(
          task,
          config,
          abortController.signal,
          logId
        );
      }

      config.onProgress(
        task.id,
        task.progress || 0,
        TaskExecutionPhase.POLLING
      );

      const result = await this.pollUntilComplete(
        task.remoteId,
        task.id,
        config,
        abortController.signal,
        logId // ä¼ é€’åŸå§‹æ—¥å¿— IDï¼Œè½®è¯¢å®Œæˆæ—¶ä¼šæ›´æ–°åŸå§‹æ—¥å¿—
      );

      return result;
    } finally {
      this.cleanup(task.id);
    }
  }

  /**
   * Cancel video generation
   */
  cancel(taskId: string): void {
    this.cleanup(taskId);
  }

  private isKlingModel(model?: string): boolean {
    return !!model && model.startsWith('kling');
  }

  private normalizeKlingBaseUrl(baseUrl: string): string {
    const trimmed = baseUrl.replace(/\/$/, '');
    return trimmed.endsWith('/v1') ? trimmed.slice(0, -3) : trimmed;
  }

  private deriveAspectRatio(size?: string): string | undefined {
    if (!size || !size.includes('x')) return undefined;
    const [wRaw, hRaw] = size.split('x');
    const width = Number(wRaw);
    const height = Number(hRaw);
    if (!width || !height) return undefined;
    const gcd = (a: number, b: number): number => (b === 0 ? a : gcd(b, a % b));
    const div = gcd(width, height);
    return `${width / div}:${height / div}`;
  }

  private async executeKling(
    task: SWTask,
    config: HandlerConfig,
    signal: AbortSignal
  ): Promise<TaskResult> {
    config.onProgress(task.id, 0, TaskExecutionPhase.SUBMITTING);

    const { taskId, logId, action2 } = await this.submitKlingVideoGeneration(
      task,
      config,
      signal
    );

    config.onRemoteId(task.id, taskId);
    config.onProgress(task.id, 5, TaskExecutionPhase.POLLING);

    return await this.pollKlingUntilComplete(
      taskId,
      action2,
      task.id,
      config,
      signal,
      logId
    );
  }

  private async resumeKling(
    task: SWTask,
    config: HandlerConfig,
    signal: AbortSignal,
    logId?: string
  ): Promise<TaskResult> {
    const action2: 'text2video' | 'image2video' =
      ((task.params as any)?.klingAction2 as
        | 'text2video'
        | 'image2video'
        | undefined) ||
      ((task.params as any)?.uploadedImages?.length > 0 ||
      (task.params as any)?.referenceImages?.length > 0
        ? 'image2video'
        : 'text2video');

    return await this.pollKlingUntilComplete(
      task.remoteId!,
      action2,
      task.id,
      config,
      signal,
      logId
    );
  }

  private async submitKlingVideoGeneration(
    task: SWTask,
    config: HandlerConfig,
    signal: AbortSignal
  ): Promise<KlingSubmitResult> {
    const { videoConfig } = config;
    const { params } = task as any;

    const refUrls = mergeReferenceImages({
      referenceImages: params.referenceImages as string[] | undefined,
      uploadedImages: params.uploadedImages as any[] | undefined,
      inputReference: params.inputReference as string | undefined,
      inputReferences: params.inputReferences as any[] | undefined,
    });

    const action2: 'text2video' | 'image2video' =
      (params.klingAction2 as 'text2video' | 'image2video' | undefined) ||
      (refUrls.length > 0 ? 'image2video' : 'text2video');

    if (action2 === 'image2video' && refUrls.length === 0) {
      throw new Error('Kling image2video requires a reference image');
    }

    const baseUrl = this.normalizeKlingBaseUrl(videoConfig.baseUrl);
    const aspectRatio =
      params.aspect_ratio || this.deriveAspectRatio(params.size);
    const duration = params.duration || params.seconds;

    const body = {
      model_name: params.model || 'kling-v1-5',
      prompt: params.prompt,
      image: refUrls[0],
      aspect_ratio: aspectRatio,
      duration: duration ? String(duration) : undefined,
      ...(params.params || {}),
    };

    const { debugFetch } = await import('../debug-fetch');
    const { startLLMApiLog, failLLMApiLog } = await import('../llm-api-logger');

    const startTime = Date.now();
    const logId = startLLMApiLog({
      endpoint: `/kling/v1/videos/${action2}`,
      model: params.model || 'kling-v1-5',
      taskType: 'video',
      prompt: params.prompt as string,
      requestBody: JSON.stringify(body, null, 2),
      hasReferenceImages: refUrls.length > 0,
      referenceImageCount: refUrls.length,
      taskId: task.id,
    });

    const response = await debugFetch(
      `${baseUrl}/kling/v1/videos/${action2}`,
      {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          ...(videoConfig.apiKey
            ? { Authorization: `Bearer ${videoConfig.apiKey}` }
            : {}),
        },
        body: JSON.stringify(body),
        signal,
      },
      {
        label: `ğŸ¬ æäº¤ Kling è§†é¢‘ç”Ÿæˆ (${params.model || 'kling-v1-5'})`,
        logResponseBody: true,
      }
    );

    if (!response.ok) {
      const errorText = await response.text();
      failLLMApiLog(logId, {
        httpStatus: response.status,
        duration: Date.now() - startTime,
        errorMessage: errorText,
        responseBody: errorText,
      });
      throw new Error(
        `Kling submission failed: ${response.status} - ${errorText}`
      );
    }

    const data = await response.json();
    const taskId = data?.data?.task_id;
    if (!taskId) {
      throw new Error('Kling submission missing task_id');
    }

    return { taskId, logId, action2 };
  }

  private async pollKlingUntilComplete(
    taskId: string,
    action2: 'text2video' | 'image2video',
    localTaskId: string,
    config: HandlerConfig,
    signal: AbortSignal,
    logId?: string
  ): Promise<TaskResult> {
    const { videoConfig } = config;
    const { debugFetch } = await import('../debug-fetch');
    const { completeLLMApiLog, failLLMApiLog } = await import(
      '../llm-api-logger'
    );
    const startTime = Date.now();
    const baseUrl = this.normalizeKlingBaseUrl(videoConfig.baseUrl);

    for (let attempt = 0; attempt < 1080; attempt += 1) {
      await new Promise((resolve) => setTimeout(resolve, 5000));

      const response = await debugFetch(
        `${baseUrl}/kling/v1/videos/${action2}/${taskId}`,
        {
          method: 'GET',
          headers: videoConfig.apiKey
            ? { Authorization: `Bearer ${videoConfig.apiKey}` }
            : undefined,
          signal,
        },
        {
          label: `ğŸ¬ æŸ¥è¯¢ Kling è§†é¢‘ä»»åŠ¡ (${taskId})`,
          logResponseBody: true,
        }
      );

      if (!response.ok) {
        const errorText = await response.text();
        if (logId) {
          failLLMApiLog(logId, {
            httpStatus: response.status,
            duration: Date.now() - startTime,
            errorMessage: errorText,
            responseBody: errorText,
          });
        }
        throw new Error(
          `Kling query failed: ${response.status} - ${errorText}`
        );
      }

      const data = await response.json();
      const status = data?.data?.task_status;

      if (status === 'succeed') {
        const videoUrl = data?.data?.task_result?.videos?.[0]?.url;
        if (!videoUrl) {
          throw new Error('No video URL in Kling response');
        }

        if (logId) {
          completeLLMApiLog(logId, {
            httpStatus: 200,
            duration: Date.now() - startTime,
            resultType: 'video',
            resultCount: 1,
            resultUrl: videoUrl,
            responseBody: JSON.stringify(data),
          });
        }

        return {
          url: videoUrl,
          format: 'mp4',
          size: 0,
          duration:
            parseFloat(data?.data?.task_result?.videos?.[0]?.duration || '0') ||
            0,
        };
      }

      if (status === 'failed') {
        const message =
          data?.data?.task_status_msg || 'Kling generation failed';
        if (logId) {
          failLLMApiLog(logId, {
            duration: Date.now() - startTime,
            errorMessage: message,
            responseBody: JSON.stringify(data),
          });
        }
        throw new Error(message);
      }

      config.onProgress(
        localTaskId,
        5 + Math.min(90, attempt * 0.1),
        TaskExecutionPhase.POLLING
      );
    }

    if (logId) {
      failLLMApiLog(logId, {
        duration: Date.now() - startTime,
        errorMessage: 'Kling generation timeout',
      });
    }
    throw new Error('Kling generation timeout');
  }

  /**
   * Submit video generation request
   */
  private async submitVideoGeneration(
    task: SWTask,
    config: HandlerConfig,
    signal: AbortSignal
  ): Promise<SubmitResult> {
    const { videoConfig } = config;
    const { params } = task;

    // Build form data
    const formData = new FormData();
    formData.append('model', params.model || 'veo3');
    formData.append('prompt', params.prompt);

    if (params.duration) {
      formData.append('seconds', String(params.duration));
    }

    if (params.size) {
      formData.append('size', params.size);
    }

    // ä½¿ç”¨é€šç”¨å‡½æ•°åˆå¹¶å‚è€ƒå›¾ç‰‡
    const refUrls = mergeReferenceImages({
      referenceImages: params.referenceImages as string[] | undefined,
      uploadedImages: params.uploadedImages as any[] | undefined,
      inputReference: params.inputReference as string | undefined,
      inputReferences: params.inputReferences as any[] | undefined,
    });

    // å¤„ç†å‚è€ƒå›¾ç‰‡ï¼šè·å– Blobï¼Œè£å‰ªåˆ°ç›®æ ‡å°ºå¯¸ï¼Œç„¶åæ·»åŠ åˆ° FormData
    // åŒæ—¶æ”¶é›†è£å‰ªåçš„å›¾ç‰‡ä¿¡æ¯ç”¨äºæ—¥å¿—
    const { getImageInfo } = await import('../utils/media-generation-utils');
    const referenceImageInfos: LLMReferenceImage[] = [];

    if (refUrls.length > 0) {
      // è§£æç›®æ ‡å°ºå¯¸
      const targetSize = params.size ? parseSize(params.size as string) : null;

      for (let i = 0; i < refUrls.length; i++) {
        const url = refUrls[i];
        try {
          // ä½¿ç”¨é€šç”¨å‡½æ•°ä»ç¼“å­˜è·å–å›¾ç‰‡
          let blob = await fetchImageWithCache(url, signal);
          if (blob) {
            // å¦‚æœæŒ‡å®šäº†ç›®æ ‡å°ºå¯¸ï¼Œè£å‰ªå›¾ç‰‡åˆ°åŒ¹é…çš„å®½é«˜æ¯”
            if (targetSize) {
              blob = await cropImageToAspectRatio(
                blob,
                targetSize.width,
                targetSize.height
              );
            }

            // è·å–è£å‰ªåçš„å›¾ç‰‡ä¿¡æ¯ç”¨äºæ—¥å¿—
            try {
              const info = await getImageInfo(blob, signal);
              referenceImageInfos.push({
                url: info.url,
                size: info.size,
                width: info.width,
                height: info.height,
              });
            } catch (err) {
              console.warn(
                `[VideoHandler] Failed to get cropped image info for log`,
                err
              );
              referenceImageInfos.push({
                url,
                size: blob.size,
                width: 0,
                height: 0,
              });
            }

            formData.append('input_reference', blob, `reference-${i + 1}.png`);
          } else {
            // ç¼“å­˜å’Œç½‘ç»œéƒ½å¤±è´¥æ—¶ï¼Œå›é€€åˆ°å‘é€ URL
            console.warn(
              `[VideoHandler] Failed to get reference image: ${url}`
            );
            formData.append('input_reference', url);
            referenceImageInfos.push({ url, size: 0, width: 0, height: 0 });
          }
        } catch (err) {
          console.warn(
            `[VideoHandler] Error fetching reference image: ${url}`,
            err
          );
          formData.append('input_reference', url);
          referenceImageInfos.push({ url, size: 0, width: 0, height: 0 });
        }
      }
    }

    // Import loggers
    const { debugFetch } = await import('../debug-fetch');
    const { startLLMApiLog, completeLLMApiLog, failLLMApiLog } = await import(
      '../llm-api-logger'
    );

    const startTime = Date.now();
    const model = (params.model as string) || 'veo3';

    // æ„å»ºè¯·æ±‚å‚æ•°çš„æ—¥å¿—è¡¨ç¤ºï¼ˆFormData æ— æ³•ç›´æ¥åºåˆ—åŒ–ï¼‰
    const requestParamsForLog = {
      model,
      prompt: params.prompt,
      ...(params.duration && { seconds: params.duration }),
      ...(params.size && { size: params.size }),
      ...(refUrls.length > 0 && {
        input_reference: `[${refUrls.length} images]`,
      }),
    };

    const logId = startLLMApiLog({
      endpoint: '/videos',
      model,
      taskType: 'video',
      prompt: params.prompt as string,
      requestBody: JSON.stringify(requestParamsForLog, null, 2),
      hasReferenceImages: refUrls.length > 0,
      referenceImageCount: refUrls.length,
      referenceImages: referenceImageInfos,
      taskId: task.id,
    });

    // Use debugFetch for logging
    const response = await debugFetch(
      `${videoConfig.baseUrl}/videos`,
      {
        method: 'POST',
        headers: videoConfig.apiKey
          ? { Authorization: `Bearer ${videoConfig.apiKey}` }
          : undefined,
        body: formData,
        signal,
      },
      {
        label: `ğŸ¬ æäº¤è§†é¢‘ç”Ÿæˆ (${model})`,
        logResponseBody: true,
      }
    );

    if (!response.ok) {
      const errorText = await response.text();
      failLLMApiLog(logId, {
        httpStatus: response.status,
        duration: Date.now() - startTime,
        errorMessage: errorText,
        responseBody: errorText,
      });
      throw new Error(
        `Video submission failed: ${response.status} - ${errorText}`
      );
    }

    const data = await response.json();

    // è®°å½• remoteId åˆ°æ—¥å¿—ï¼Œä»¥ä¾¿åœ¨ SW é‡å¯æ—¶æ¢å¤
    if (data.id) {
      const { updateLLMApiLogMetadata } = await import('../llm-api-logger');
      updateLLMApiLogMetadata(logId, {
        remoteId: data.id,
        responseBody: JSON.stringify(data),
        httpStatus: response.status,
      });
    }

    // æ³¨æ„ï¼šè¿™é‡Œä¸è°ƒç”¨ completeLLMApiLogï¼Œå› ä¸ºè§†é¢‘è¿˜åœ¨å¼‚æ­¥ç”Ÿæˆä¸­
    // æœ€ç»ˆç»“æœä¼šåœ¨ pollUntilComplete å®Œæˆåæ›´æ–°

    return { response: data, logId };
  }

  /**
   * Poll video status until completion
   * ä½¿ç”¨é€šç”¨çš„è½®è¯¢é€»è¾‘ï¼Œä½†ä¿æŒä»»åŠ¡çº§åˆ«çš„è¿›åº¦å›è°ƒ
   */
  private async pollUntilComplete(
    videoId: string,
    taskId: string,
    config: HandlerConfig,
    signal: AbortSignal,
    logId?: string
  ): Promise<TaskResult> {
    const { videoConfig } = config;
    const startTime = Date.now();

    try {
      // ä½¿ç”¨é€šç”¨è½®è¯¢å‡½æ•°
      const result = await pollVideoUntilComplete(
        videoConfig.baseUrl,
        videoId,
        {
          onProgress: (progress, phase) => {
            config.onProgress(taskId, progress, phase);
          },
          signal,
          apiKey: videoConfig.apiKey,
          interval: 5000,
          maxAttempts: 1080, // 90 minutes
        }
      );

      const videoUrl = result.video_url || result.url;
      if (!videoUrl) {
        throw new Error('No video URL in completed response');
      }

      // æ›´æ–° LLM API æ—¥å¿—ï¼Œæ·»åŠ æœ€ç»ˆçš„è§†é¢‘ URL
      if (logId) {
        const { completeLLMApiLog } = await import('../llm-api-logger');
        completeLLMApiLog(logId, {
          httpStatus: 200,
          duration: Date.now() - startTime,
          resultType: 'video',
          resultCount: 1,
          resultUrl: videoUrl,
          responseBody: JSON.stringify(result),
        });
      }

      return {
        url: videoUrl,
        format: 'mp4',
        size: 0,
        width: result.width,
        height: result.height,
        duration: parseInt(result.seconds || '0') || 0,
      };
    } catch (error) {
      // æ›´æ–° LLM API æ—¥å¿—ï¼Œè®°å½•å¤±è´¥
      if (logId) {
        const { failLLMApiLog } = await import('../llm-api-logger');
        failLLMApiLog(logId, {
          duration: Date.now() - startTime,
          errorMessage: error instanceof Error ? error.message : String(error),
        });
      }
      throw error;
    }
  }

  /**
   * Cleanup resources
   */
  private cleanup(taskId: string): void {
    const controller = this.abortControllers.get(taskId);
    if (controller) {
      controller.abort();
      this.abortControllers.delete(taskId);
    }

    const interval = this.pollingIntervals.get(taskId);
    if (interval) {
      clearTimeout(interval);
      this.pollingIntervals.delete(taskId);
    }
  }
}
